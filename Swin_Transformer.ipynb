{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObf9JQgUCDj1EQ/kWfKgRs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agercodes/Swin_Transformer/blob/main/Swin_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install timm"
      ],
      "metadata": {
        "id": "85Ap4vuBgwzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Dependencies"
      ],
      "metadata": {
        "id": "O7TYidSiivle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from timm.models.layers import PatchEmbed\n",
        "from timm.models.swin_transformer import PatchMerging, SwinTransformerBlock"
      ],
      "metadata": {
        "id": "i9KUUOH1hT8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patch Partition/Embedding"
      ],
      "metadata": {
        "id": "NT8Nchl3g4mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 224, 224)\n",
        "patch_embed = PatchEmbed(img_size=224, patch_size=4, embed_dim=96)\n",
        "patch_embed(x).shape"
      ],
      "metadata": {
        "id": "QbXNJNvpgzZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patch Merging"
      ],
      "metadata": {
        "id": "7eNnE6ZwhJpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, input_resolution, dim, out_dim=None, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.input_resolution = input_resolution\n",
        "        self.dim = dim\n",
        "        self.out_dim = out_dim or 2 * dim\n",
        "        self.norm = norm_layer(4 * dim)\n",
        "        self.reduction = nn.Linear(4 * dim, self.out_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: B, H*W, C\n",
        "        B: Batch size\n",
        "        \"\"\"\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = x.shape\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
        "\n",
        "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
        "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eBDyWnrMhq2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 56*56, 96)\n",
        "l = PatchMerging(input_resolution=(56, 56), dim=96, out_dim=192, norm_layer=nn.LayerNorm)\n",
        "l(x).shape"
      ],
      "metadata": {
        "id": "2ZBkIUsag9xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Swin Transformer Block"
      ],
      "metadata": {
        "id": "JrWIkBiGh7Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 56*56, 96)\n",
        "t_1 = SwinTransformerBlock(dim=96, input_resolution=(56, 56))\n",
        "t_2 = SwinTransformerBlock(dim=96, input_resolution=(56, 56), shift_size=3)\n",
        "t_1(x).shape, t_2(t_1(x)).shape"
      ],
      "metadata": {
        "id": "UkO9OCBnhjjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Window Partitioning"
      ],
      "metadata": {
        "id": "sMsvQ8CSiXFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, H, W, C)\n",
        "        window_size (int): window size\n",
        "\n",
        "    Returns:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "    \"\"\"\n",
        "    B, H, W, C = x.shape\n",
        "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
        "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
        "    return windows"
      ],
      "metadata": {
        "id": "AxZZFryNiV3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}